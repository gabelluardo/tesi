\chapter{Analisi dei Benchmark}
\label{sec:analisys}

\section{Considerazioni sui Risultati}

% CUDA è ottimizzato per girare su NVIDIA e nonostante questo vulkan a volte va meglio

Considerando che i benchmark sono stati eseguiti su hardware prodotto da NVIDIA e con CUDA che è un framework proprietario sviluppato da NVIDIA stessa, il dato sorprendente è che Vulkan abbia prestazioni paragonabili e in alcuni casi migliori. Soprattutto per quanto riguarda i benchmark sulle moltiplicazioni di matrici in fig. \ref{fig:bench_f64} si può notare come l'esecuzione su dati a virgola mobile con doppia precisione sia ottimizzata meglio in CUDA, anche se la differenza della media dei tempi è comunque nell'ordine di 1 millisecondo. Se si prende in considerazione anche il trasferimento dei dati tra host e device, Vulkan risulta essere più performante su tutti i tipi di dato, dimezzando addirittura i tempi di esecuzione. Per quanto riguarda i dati sulla somma dei vettori, in tutti i benchmark Vulkan risulta meno efficiente rispetto a CUDA, ma comunque con una differenza prestazione non troppo marcata. Questo è dovuto alla natura stessa del benchmark, poiché il caricamento del contesto e l'inizializzazione delle risorse thread richiede tempo per la quantità di elementi presi in esame, il tutto per eseguire una singola operazione di somma: è indubbio che CUDA sia ottimizzato in modo migliore su questo punto di vista. In contesti reali si sarebbe eseguito un loop-unrolling lato kernel per diminuire l'overhead dovuto alla gestione dei thread. Inoltre, i risultati ottenuti potrebbero essere influenzati dal fatto che i benchmark sono stati eseguiti su un singolo dispositivo e non su un cluster di GPU, quindi non si può escludere che i risultati possano variare in base al numero di GPU presenti nel sistema. 

% vulkan buono per la portabilità e le prestazioni

I risultati ottenuti evidenziano che Vulkan può essere considerata un'alternativa valida a CUDA per lo sviluppo di applicazioni di alto livello. Inoltre, Vulkan è un'API open-source, quindi non è legata a un singolo produttore e può essere utilizzata su hardware di diversi produttori. Questo è un vantaggio non trascurabile, poiché permette di sviluppare applicazioni che possono essere eseguite su hardware diverso senza dover riscrivere il codice. Un altro elemento importante da considerare è che mentre lo scope principale di CUDA è il computing, quello di Vulkan è la grafica. Nonostante questo, i risultati ottenuti dimostrano che le ottimizzazioni di Vulkan lo rendono in grado di essere utilizzato per applicazioni di computing generale. Inoltre, Vulkan è in grado di estendere le funzionalità fornite tramite estensioni, per adattarsi a nuove esigenze e migliorare le prestazioni.


\section{Considerazioni sulla Development Experience}

% descrivere l'ambiente e le estensioni usate (nvidia insights, vscode, ssh)

Per quanto riguarda lo sviluppo dei benchmark, in pratica può essere considerato come lo sviluppo di due applicazioni uguali in CUDA e in Vulkan. Come ambiente di sviluppo è stato usato \textit{Visual Studio Code} collegato tramite \textit{ssh} alla macchina di test, in modo da poter scrivere il codice e compilarlo direttamente sul dispositivo. Per quanto riguarda le estensioni, è stato utilizzato NVIDIA Nsight \cite[]{NVIDIA:nsight} per il debug sia di CUDA che di Vulkan e linter e formatter presenti per i linguaggi. Si è usato il Vulkan SDK di LunarG \cite[]{KG:vulkan_sdk} per la compilazione e l'esecuzione, ma senza l'uso del \textit{Validation Layer}, che permette fare dei controlli di validazione degli shader a compile time, data la semplicità degli shader sviluppati.

% i tool di sviluppo sono buoni

Per lo sviluppo del benchmark di Vulkan, l'ecosistema Rust fornisce, out of the box, una serie di strumenti per semplificare lo sviluppo:

\begin{itemize}
    \item \textit{Cargo}: package manager che permette di gestire le dipendenze e di compilare il codice
    \item \textit{rustfmt}: formatter per il codice sorgente
    \item \textit{clippy}: linter per il codice sorgente
    \item \textit{rust-analyzer}: \gls{LSP} per l'autocompletamento e la navigazione del codice
    \item \textit{crates.io} e \textit{docs.rs}: repository di librerie e documentazione
\end{itemize}

L'ecosistema Rust e i tool offerti offrono benefici in termini di esperienza di sviluppo al programmatore, permettendo di concentrarsi sullo sviluppo del codice e non sulla configurazione dell'ambiente di sviluppo. Quindi con la sola esclusione di NVIDIA Nsight, si è in grado di sviluppare facilmente e usando soltanto tool open-source applicazioni di alto livello.

\newpage

Per quanto riguarda lo sviluppo di CUDA, non si può dire lo stesso. Partendo dal fatto che CUDA di per sè è un ambiente proprietario, ad esempio, del compilatore \textit{nvcc} non si possono conoscere le ottimizzazioni che vengono applicate al codice. Inoltre, essendo praticamente un ecosistema che si rifà a C++, la mancanza di tool standardizzati e ufficialmente mantenuti dalla \textit{Standard C++ Foundation} ha portato a una frammentazione dell'ecosistema, che obbliga lo sviluppatore a scegliere a monte tra i vari sistemi di sviluppo come, ad esempio, \textit{make}, \textit{cmake}, \textit{ninja}, tra i vari stili di formattazione usati e tra i vari linter disponibili. Inoltre, la mancanza di un package manager ufficiale obbliga il programmatore a gestire le dipendenze manualmente, con la conseguente necessità di conoscere a priori le librerie da utilizzare e come installarle, col rischio di avere un sistema di building non riproducibile e poco portabile.

A parte queste considerazioni, una volta impostati i tool e l'ambiente, lo sviluppo con CUDA è molto più facile e veloce rispetto a Vulkan. L'avere un 
compilatore che estende il linguaggio C++ con delle keyword che isolano il 
codice kernel da quello host, permette di scrivere codice molto più simile a quello che si scriverebbe in C++ puro. Quanto visto nel capitolo \ref{sec:benchmark} per l'uso dei generics è esplicativo in tal senso. Inoltre, il fatto che CUDA sia un framework proprietario permette di avere un supporto molto più ampio rispetto a Vulkan, che è un'API open-source.

% vulkan è verboso

Per quanto riguarda Vulkan, la sua natura di API a basso livello rende lo sviluppo più complesso rispetto a CUDA. La necessità di gestire manualmente la creazione e allocazione delle risorse, come ad esempio le pipeline o i buffer, rende il codice molto più verboso e complesso. Sebbene parte di questa complessità sia attenuata da Rust che si occupa di della distruzione delle risorse e la gestione della memoria, in confronto allo sviluppo di CUDA, lo sviluppo di Vulkan risulta più complesso e richiede una maggiore attenzione. Inoltre, la necessità di dover scrivere gli shader in un linguaggio specifico, come GLSL, richiede di dover conoscere un linguaggio di programmazione in più rispetto a CUDA, che permette di scrivere i kernel praticamente in C++.
Questi problemi potrebbero essere risolti scrivendo libreria che aumentino il grado di astrazione e che permettano di scrivere codice più simile a quello che si scriverebbe in CUDA, ma questo è uno sforzo non da poco e non è stato intrapreso ai fini del benchmark.

% CUDA è più semplice ma scrivere in C++ è difficile

In conclusione, sia CUDA che Vulkan hanno punti di forza e debolezze per quanto riguarda la GPGPU: quelle di CUDA derivano in larga parte dall'integrazione con C++ e il suo ecosistema, mentre quelli di Vulkan dalla sua natura di API a basso livello, più focalizzate sulla grafica che sul computing. Per quanto riguarda lo sviluppo di applicazioni multi-piattaforma, comunque, Vulkan è una scelta obbligata e i risultati ottenuti dimostrano che è in grado di competere con CUDA in termini di prestazioni. Sebbene siano in sviluppo librerie per compilare direttamente codice Rust in SPIR-V, come ad esempio \cite[]{KG:rspirv}, che potrebbero rendere lo sviluppo di applicazioni Vulkan più semplice, al momento non è possibile fare un confronto diretto tra le due API in termini di sviluppo. Inoltre il focus che sta mettendo NVIDIA su CUDA e il suo ecosistema, come dimostrato dal recente rilascio di \textit{NVIDIA HPC SDK} \cite[]{NVIDIA:hpc_sdk}, dimostra che CUDA è ancora la scelta principale per lo sviluppo di applicazioni di GPGPU. 

